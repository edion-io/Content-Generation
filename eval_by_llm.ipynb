{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = pd.read_csv(\"data/questions.csv\")\n",
    "instructions = pd.read_csv(\"data/instructions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8312, 8312)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions), len(instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Divide the letter \"N\" into halves.\\n\\n[STRDGM] The letter \"N\". [STPDGM]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions.iloc[7598][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>exercise_type</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>grade_level</th>\n",
       "      <th>modifier</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Practical Exercise, Activity</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>Create a document file called 'My hobby' to us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Algorithm Writing Exercise</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>Exercise on making a toy horse</td>\n",
       "      <td>Write an algorithm for making a toy horse. \\nW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Short Answer Exercise</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>With Material</td>\n",
       "      <td>What does ‘algorithm' mean? Write or say the a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Short Answer Exercise</td>\n",
       "      <td>D</td>\n",
       "      <td>5</td>\n",
       "      <td>With Material</td>\n",
       "      <td>Imagine that the x coordinate of an apple is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Programming Exercise</td>\n",
       "      <td>D</td>\n",
       "      <td>5</td>\n",
       "      <td>With Material, Exercise on sprite creation and...</td>\n",
       "      <td>Add a sprite (for example, an apple) to your s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            subject                 exercise_type difficulty grade_level  \\\n",
       "0  Computer Science  Practical Exercise, Activity          D           2   \n",
       "1  Computer Science    Algorithm Writing Exercise          D           2   \n",
       "2  Computer Science         Short Answer Exercise          D           2   \n",
       "3  Computer Science         Short Answer Exercise          D           5   \n",
       "4  Computer Science          Programming Exercise          D           5   \n",
       "\n",
       "                                            modifier  \\\n",
       "0                                                  M   \n",
       "1                     Exercise on making a toy horse   \n",
       "2                                      With Material   \n",
       "3                                      With Material   \n",
       "4  With Material, Exercise on sprite creation and...   \n",
       "\n",
       "                                             content  \n",
       "0  Create a document file called 'My hobby' to us...  \n",
       "1  Write an algorithm for making a toy horse. \\nW...  \n",
       "2  What does ‘algorithm' mean? Write or say the a...  \n",
       "3  Imagine that the x coordinate of an apple is a...  \n",
       "4  Add a sprite (for example, an apple) to your s...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(instructions)):\n",
    "    q_exercise_types = questions.iloc[i][\"exercise_type\"].split(\",\")\n",
    "    # print(q_exercise_types)\n",
    "    [t.lower() in instructions.iloc[i][\"Input\"].lower() for t in q_exercise_types]\n",
    "    if all(t.lower() in instructions.iloc[i][\"Input\"].lower() for t in q_exercise_types):\n",
    "        # print(True, i)\n",
    "        pass\n",
    "    else:\n",
    "        print(False, i)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have a dataframe with 5 columns: \"subject\"\t\"exercise_type\"\t\"difficulty\"\t\"grade_level\"\t\"modifier\"\t\"content\".\n",
    "Now I want to randomly sample 2 rows and calculate the number of matching columns (\"content\" is exlcluded), for instance, row1[\"subject\"] == row2[\"subject\"] --> 1 matching\n",
    "Create a dataframe to store sample results, each result contains \"num_matched_column\", \"row1.index\", \"row2.index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_matched_column': 4, 'row1.index': 6359, 'row2.index': 6359}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Define function to sample and calculate matches\n",
    "def sample_and_match(df):\n",
    "\n",
    "    # With 0.2 probability take the input output from the same sample to have score of 4\n",
    "    if random.random() < 0.2:\n",
    "        sampled_rows = df.sample(1)\n",
    "        idx1 = idx2 = sampled_rows.index[0]\n",
    "        num_matched_columns = 4\n",
    "        result = {\n",
    "            'num_matched_column': num_matched_columns,\n",
    "            'row1.index': idx1,\n",
    "            'row2.index': idx2\n",
    "        }\n",
    "    else:\n",
    "        # Sample 2 rows\n",
    "        sampled_rows = df.sample(2)\n",
    "        \n",
    "        # Extract the indices of the sampled rows\n",
    "        idx1, idx2 = sampled_rows.index\n",
    "        \n",
    "        # Exclude \"content\" and \"difficulty\" column from the comparison\n",
    "        cols_to_compare = df.columns.difference(['content', 'difficulty'])\n",
    "        \n",
    "        # Count the number of matching columns (excluding \"content\" and \"difficulty\")\n",
    "        num_matched_columns = np.sum(sampled_rows.iloc[0][cols_to_compare] == sampled_rows.iloc[1][cols_to_compare])\n",
    "        \n",
    "        # Create a result dictionary\n",
    "        result = {\n",
    "            'num_matched_column': num_matched_columns,\n",
    "            'row1.index': idx1,\n",
    "            'row2.index': idx2\n",
    "        }\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "result_df = sample_and_match(questions)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(subject                                                Mathematics\n",
       " exercise_type                                  Arithmetic Exercise\n",
       " difficulty                                                       D\n",
       " grade_level                                                      2\n",
       " modifier         With Illustration, Exercise on counting, Multi...\n",
       " content          Start at 0. Draw 4 jumps of 5 on a number line...\n",
       " Name: 6359, dtype: object,\n",
       " subject                                                Mathematics\n",
       " exercise_type                                  Arithmetic Exercise\n",
       " difficulty                                                       D\n",
       " grade_level                                                      2\n",
       " modifier         With Illustration, Exercise on counting, Multi...\n",
       " content          Start at 0. Draw 4 jumps of 5 on a number line...\n",
       " Name: 6359, dtype: object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions.iloc[result_df[\"row1.index\"]], questions.iloc[result_df[\"row2.index\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_matched_column\n",
      "0    10434\n",
      "1     4442\n",
      "2      978\n",
      "3      113\n",
      "4     4033\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create 100 samples and store results in a DataFrame\n",
    "results = []\n",
    "for _ in range(20000):\n",
    "    result = sample_and_match(questions)\n",
    "    results.append(result)\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "# print(results_df)\n",
    "\n",
    "# Display the distribution of different values of num_matched_column\n",
    "distribution = results_df['num_matched_column'].value_counts().sort_index()\n",
    "\n",
    "# Display the distribution\n",
    "print(distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_matched_column\n",
      "0    100\n",
      "1    100\n",
      "2    100\n",
      "3    100\n",
      "4    100\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2576612/3838881311.py:7: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = grouped.apply(lambda x: x.sample(min(len(x), sample_size), replace=False)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# Sample 50 values from each category of num_matched_column\n",
    "def sample_from_each_category(df, column, sample_size=50):\n",
    "    # Group by the specified column (num_matched_column)\n",
    "    grouped = df.groupby(column)\n",
    "    \n",
    "    # Sample up to 'sample_size' rows from each group\n",
    "    sampled_df = grouped.apply(lambda x: x.sample(min(len(x), sample_size), replace=False)).reset_index(drop=True)\n",
    "    \n",
    "    return sampled_df\n",
    "\n",
    "# Apply the function to sample 50 rows from each category of num_matched_column\n",
    "sampled_results_df = sample_from_each_category(results_df, 'num_matched_column', sample_size=100)\n",
    "\n",
    "# Display the new DataFrame with the sampled results\n",
    "print(sampled_results_df['num_matched_column'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampled_results_df.to_csv(\"data/coherence_eval.csv\", index=False)\n",
    "sampled_results_df = pd.read_csv(\"data/coherence_eval.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample \"Input\" based on row1.index and \"Output\" based on row2.index\n",
    "sampled_results_df['Input'] = sampled_results_df['row1.index'].apply(lambda idx: instructions.loc[idx, 'Input'])\n",
    "sampled_results_df['Output'] = sampled_results_df['row2.index'].apply(lambda idx: instructions.loc[idx, 'Output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_data = sampled_results_df.sample(frac=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Set up your OpenAI API key\n",
    "openai.api_key = \"sk-proj-ltmkMm6qZ8oQCsusN5IOT3BlbkFJmsPopivPYwLtY7jlx5Pl\"\n",
    "\n",
    "# Example to generate text using GPT-4\n",
    "def generate_text(sys_prompt, user_prompt):\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4o\",  # Use \"gpt-4-turbo\" for a faster, cheaper alternative\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            max_tokens=150,  # Limit the number of tokens in the output\n",
    "            temperature=0.7,  # Adjust the creativity level of the model\n",
    "            n=1,  # Number of completions to generate\n",
    "            stop=None  # Stop generation based on special characters or tokens\n",
    "        )\n",
    "        return response['choices'][0]['message']['content'].strip()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "prompt = \"Write a short story about a robot learning to play the piano.\"\n",
    "generated_text = generate_text(prompt)\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are an exercise generation evaluator. \n",
    "Given an query-answer pair, where the query is a demand and the answer is the generated exercise,\n",
    "you will score the coherence of the excercise from 4 perspectives:\n",
    "- Subject: score 1 if the subject is correct else 0.\n",
    "- Exercise type: score 1 if the exercise type is correct else 0.\n",
    "- Grade level: score 1 if the grade level is close to the given according to 1-12 Amecian grade system else 0.\n",
    "- Modification: score 1 if the specific details matches the requirement else 0.\n",
    "Don't be too strict to each criterion, you can give them score as long as it is full filled in a cetain level. Your final score is the sum of all these four scores. Provide your answer in the following format:\n",
    "\n",
    "{\"Subject score\": x, \"Exercise type score\": x, \"Grade level\": x, \"Modification score\": x, \"Total score\": x}\"\"\"\n",
    "\n",
    "def parse_response(response):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_scores = []\n",
    "for index, row in sampled_results_df.iterrows():\n",
    "    input, output, score = row['Input'], row['Output'], row['num_matched_column']\n",
    "    user_prompt = f\"Query: \\\"{input}\\\"\\n\\nAnswer: \\\"{output}\\\"\"\n",
    "    response = generate_text(system_prompt, user_prompt)\n",
    "    result = parse_response(response)\n",
    "    predict_scores.append(result[\"Total score\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_df = pd.DataFrame({\"predict_score\": predict_scores, \"true_score\": sampled_results_df['num_matched_column'].values})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse and build questions dataframe with param columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def parse_params(text):\n",
    "    text = text.strip()\n",
    "    # Find content '(...)' or S or T or D or G or M or number (5 params)\n",
    "    params= re.findall(r\"\\(.+?\\)|\\d+|S|T|D|G|M\", text)\n",
    "    params = [p.replace(\"(\",\"\").replace(\")\", \"\") for p in params]\n",
    "    # assert len(params) == 5, \"Parse result is not complete\"\n",
    "    assert len(params) == 5, text\n",
    "    return params\n",
    "\n",
    "with open(\"data/questions.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "text = text\n",
    "title_pattern = r\"\\([a-zA-Z].+\\).+ D .+\\n\"\n",
    "# Find all titles (questions)\n",
    "titles = re.findall(title_pattern, text)\n",
    "# Find all contents (answers)\n",
    "contents = re.split(title_pattern, text)\n",
    "contents = [content.strip() for content in contents]\n",
    "contents = contents[1:] if contents[0] == \"\" else contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "text = text\n",
    "title_pattern = r\"\\([a-zA-Z].+\\).+ D .+\\n\"\n",
    "# Find all titles (questions)\n",
    "titles = re.findall(title_pattern, text)\n",
    "# Find all contents (answers)\n",
    "contents = re.split(title_pattern, text)\n",
    "contents = [content.strip() for content in contents]\n",
    "contents = contents[1:] if contents[0] == \"\" else contents\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject, exercise_type, difficulty, grade_level, modifier = ([] for _ in range(5))\n",
    "\n",
    "for title in titles:\n",
    "    params = parse_params(title)\n",
    "    subject.append(params[0])\n",
    "    exercise_type.append(params[1])\n",
    "    difficulty.append(params[2])\n",
    "    grade_level.append(params[3])\n",
    "    modifier.append(params[4])\n",
    "\n",
    "struct_data = pd.DataFrame({\"subject\": subject, \"exercise_type\": exercise_type, \"difficulty\": difficulty,\n",
    "                             \"grade_level\": grade_level, \"modifier\": modifier, \"content\": contents})\n",
    "\n",
    "struct_data.to_csv(\"data/questions.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
